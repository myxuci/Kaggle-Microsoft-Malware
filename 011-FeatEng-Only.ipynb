{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\xiaowei.li\\appdata\\local\\continuum\\anaconda3\\envs\\myvirtualpythonenv\\lib\\importlib\\_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numba import jit\n",
    "from tqdm import tqdm\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import catboost as cat\n",
    "from datetime import datetime as dt\n",
    "import itertools\n",
    "from sklearn.externals import joblib\n",
    "from scipy.sparse import vstack, csr_matrix, save_npz, load_npz\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from dtypes import *\n",
    "import gc\n",
    "gc.enable()\n",
    "\n",
    "pd.options.display.max_columns = 999\n",
    "pd.options.display.max_rows = 100\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download Train and Test Data.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "201096"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Download Train and Test Data.\\n')\n",
    "train = pd.read_csv('../Data/train.csv', dtype=dtypes, low_memory=True)\n",
    "# train['MachineIdentifier'] = train.index.astype('uint32')\n",
    "train.loc[5244810, 'AvSigVersion'] = '1.273.1144.0'\n",
    "\n",
    "test  = pd.read_csv('../Data/test.csv',  dtype=dtypes, low_memory=True)\n",
    "# test['MachineIdentifier']  = test.index.astype('uint32')\n",
    "test.loc[6529507, 'OsBuildLab'] = '17134.1.amd64fre.rs4_release.180410-1804'\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['DIFF_AVProductsInstalled_AVProductsEnabled'] = train['AVProductsInstalled'] - train['AVProductsEnabled']\n",
    "test['DIFF_AVProductsInstalled_AVProductsEnabled'] = test['AVProductsInstalled'] - test['AVProductsEnabled']\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agg_(train, test, target_col, *args):\n",
    "    _cols = list(args)\n",
    "    _cols += [target_col]\n",
    "    df = pd.concat([train[_cols], test[_cols]], axis=0)\n",
    "    _agg_df = df.groupby(args)[target_col].nunique().reset_index()\n",
    "    \n",
    "    _new_col_name = '{}_nunique_by_{}'.format(target_col, '_'.join(args))\n",
    "    _agg_df.rename({target_col:_new_col_name}, axis=1, inplace=True)\n",
    "    train[_new_col_name] = pd.merge(train, _agg_df, on=args, how='left')[_new_col_name].fillna(0).astype(int)\n",
    "    test[_new_col_name] = pd.merge(test, _agg_df, on=args, how='left')[_new_col_name].fillna(0).astype(int)\n",
    "    \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/6 [00:00<?, ?it/s]c:\\users\\xiaowei.li\\appdata\\local\\continuum\\anaconda3\\envs\\myvirtualpythonenv\\lib\\site-packages\\ipykernel_launcher.py:5: FutureWarning: Interpreting tuple 'by' as a list of keys, rather than a single key. Use 'by=[...]' instead of 'by=(...)'. In the future, a tuple will always mean a single key.\n",
      "  \"\"\"\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [02:43<00:00, 27.17s/it]\n"
     ]
    }
   ],
   "source": [
    "for target_col in tqdm(['OrganizationIdentifier', 'GeoNameIdentifier', 'LocaleEnglishNameIdentifier', 'Census_OSInstallLanguageIdentifier', 'Census_OSUILocaleIdentifier', 'AVProductStatesIdentifier']):\n",
    "    train, test = agg_(train, test, target_col, 'CountryIdentifier', 'CityIdentifier')\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_features(df):\n",
    "\n",
    "    def extend_string(x, length):\n",
    "        return '0' * (length - len(str(x))) + str(x)\n",
    "    \n",
    "    def update_col(df, col):\n",
    "        _length = len(str(df[col].max()))\n",
    "        return df[col].apply(lambda x: extend_string(x, _length))\n",
    "        \n",
    "    df['EngineVersion_0'] = df['EngineVersion'].apply(lambda x: x.split('.')[0]).astype(int)\n",
    "    df['EngineVersion_1'] = df['EngineVersion'].apply(lambda x: x.split('.')[1]).astype(int)\n",
    "    df['EngineVersion_2'] = df['EngineVersion'].apply(lambda x: x.split('.')[2]).astype(int)\n",
    "    df['EngineVersion_3'] = df['EngineVersion'].apply(lambda x: x.split('.')[3]).astype(int)\n",
    "    \n",
    "    df['AppVersion_0'] = df['AppVersion'].apply(lambda x: x.split('.')[0]).astype(int)\n",
    "    df['AppVersion_1'] = df['AppVersion'].apply(lambda x: x.split('.')[1]).astype(int)\n",
    "    df['AppVersion_2'] = df['AppVersion'].apply(lambda x: x.split('.')[2]).astype(int)\n",
    "    df['AppVersion_3'] = df['AppVersion'].apply(lambda x: x.split('.')[3]).astype(int)\n",
    "\n",
    "    df['AvSigVersion_0'] = df['AvSigVersion'].apply(lambda x: x.split('.')[0]).astype(int)\n",
    "    df['AvSigVersion_1'] = df['AvSigVersion'].apply(lambda x: x.split('.')[1]).astype(int)\n",
    "    df['AvSigVersion_2'] = df['AvSigVersion'].apply(lambda x: x.split('.')[2]).astype(int)\n",
    "    df['AvSigVersion_3'] = df['AvSigVersion'].apply(lambda x: x.split('.')[3]).astype(int)\n",
    "\n",
    "    df['Census_OSVersion_0'] = df['Census_OSVersion'].apply(lambda x: x.split('.')[0]).astype(int)\n",
    "    df['Census_OSVersion_1'] = df['Census_OSVersion'].apply(lambda x: x.split('.')[1]).astype(int)\n",
    "    df['Census_OSVersion_2'] = df['Census_OSVersion'].apply(lambda x: x.split('.')[2]).astype(int)\n",
    "    df['Census_OSVersion_3'] = df['Census_OSVersion'].apply(lambda x: x.split('.')[3]).astype(int)\n",
    "                             \n",
    "    for col in tqdm(['EngineVersion_0', 'EngineVersion_1', 'EngineVersion_2', 'EngineVersion_3',\n",
    "                'AppVersion_0', 'AppVersion_1', 'AppVersion_2', 'AppVersion_3',\n",
    "                'AvSigVersion_0', 'AvSigVersion_1', 'AvSigVersion_2', 'AvSigVersion_3',\n",
    "                'Census_OSVersion_0', 'Census_OSVersion_1', 'Census_OSVersion_2', 'Census_OSVersion_3']):\n",
    "        df[col] = update_col(df, col)\n",
    "        df[col] = df[col].astype(str)\n",
    "                             \n",
    "    df['EngineVersion'] = df['EngineVersion_0'] + '.' + df['EngineVersion_1'] + '.' + df['EngineVersion_2'] + '.' + df['EngineVersion_3']\n",
    "    df['AppVersion'] = df['AppVersion_0'] + '.' + df['AppVersion_1'] + '.' + df['AppVersion_2'] + '.' + df['AppVersion_3']\n",
    "    df['AvSigVersion'] = df['AvSigVersion_0'] + '.' + df['AvSigVersion_1'] + '.' + df['AvSigVersion_2'] + '.' + df['AvSigVersion_3']\n",
    "    df['Census_OSVersion'] = df['Census_OSVersion_0'] + '.' + df['Census_OSVersion_1'] + '.' + df['Census_OSVersion_2'] + '.' + df['Census_OSVersion_3']\n",
    "    \n",
    "    for col in tqdm(['EngineVersion_0', 'EngineVersion_1', 'EngineVersion_2', 'EngineVersion_3',\n",
    "                    'AppVersion_0', 'AppVersion_1', 'AppVersion_2', 'AppVersion_3',\n",
    "                    'AvSigVersion_0', 'AvSigVersion_1', 'AvSigVersion_2', 'AvSigVersion_3',\n",
    "                    'Census_OSVersion_0', 'Census_OSVersion_1', 'Census_OSVersion_2', 'Census_OSVersion_3']):\n",
    "        df.drop(col, axis=1, inplace=True)\n",
    "                             \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [02:24<00:00,  9.04s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [01:01<00:00,  3.86s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [02:06<00:00,  7.92s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:49<00:00,  3.10s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "119"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = update_features(train)\n",
    "train.loc[train[train['AvSigVersion']=='0.000.0000.0'].index, 'AvSigVersion'] = np.nan\n",
    "gc.collect()\n",
    "\n",
    "test = update_features(test)\n",
    "test.loc[test[test['AvSigVersion']=='0.000.0000.0'].index, 'AvSigVersion'] = np.nan\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_previous_feats(train, test):\n",
    "    for col in tqdm(['EngineVersion', 'AppVersion', 'AvSigVersion', 'Census_OSVersion']):\n",
    "        _tmp_df = pd.DataFrame()\n",
    "        _tmp_df[col] = np.sort(np.unique(train[col].tolist() + test[col].tolist())).tolist()\n",
    "        _tmp_df['previous_{}'.format(col)] = _tmp_df[col].shift(1)\n",
    "        _tmp_df.dropna(inplace=True)\n",
    "        train = pd.merge(train, _tmp_df, on=col, how='left')\n",
    "        test = pd.merge(test, _tmp_df, on=col, how='left')\n",
    "        \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [01:24<00:00, 21.17s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test = cal_previous_feats(train, test)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(train, test):\n",
    "    \n",
    "    def group_battery(x):\n",
    "        x = x.lower()\n",
    "        if 'li' in x:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    train['Census_InternalBatteryType'] = train['Census_InternalBatteryType'].astype(str).apply(group_battery)\n",
    "    test['Census_InternalBatteryType'] = test['Census_InternalBatteryType'].astype(str).apply(group_battery)\n",
    "    \n",
    "    def rename_edition(x):\n",
    "        x = x.lower()\n",
    "        if 'core' in x:\n",
    "            return 'Core'\n",
    "        elif 'pro' in x:\n",
    "            return 'pro'\n",
    "        elif 'enterprise' in x:\n",
    "            return 'Enterprise'\n",
    "        elif 'server' in x:\n",
    "            return 'Server'\n",
    "        elif 'home' in x:\n",
    "            return 'Home'\n",
    "        elif 'education' in x:\n",
    "            return 'Education'\n",
    "        elif 'cloud' in x:\n",
    "            return 'Cloud'\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "    train['Census_OSEdition'] = train['Census_OSEdition'].astype(str)\n",
    "    test['Census_OSEdition'] = test['Census_OSEdition'].astype(str)\n",
    "    train['Census_OSEdition'] = train['Census_OSEdition'].apply(rename_edition)\n",
    "    test['Census_OSEdition'] = test['Census_OSEdition'].apply(rename_edition)\n",
    "    train['Census_OSEdition'] = train['Census_OSEdition'].astype('category')\n",
    "    test['Census_OSEdition'] = test['Census_OSEdition'].astype('category')\n",
    "\n",
    "    train['Census_OSSkuName'] = train['Census_OSSkuName'].astype(str)\n",
    "    test['Census_OSSkuName'] = test['Census_OSSkuName'].astype(str)\n",
    "    train['Census_OSSkuName'] = train['Census_OSSkuName'].apply(rename_edition)\n",
    "    test['Census_OSSkuName'] = test['Census_OSSkuName'].apply(rename_edition)\n",
    "    train['Census_OSSkuName'] = train['Census_OSSkuName'].astype('category')\n",
    "    test['Census_OSSkuName'] = test['Census_OSSkuName'].astype('category')\n",
    "\n",
    "    train['OsBuildLab'] = train['OsBuildLab'].cat.add_categories(['0.0.0.0.0-0'])\n",
    "    train['OsBuildLab'] = train['OsBuildLab'].fillna('0.0.0.0.0-0')\n",
    "    test['OsBuildLab'] = test['OsBuildLab'].cat.add_categories(['0.0.0.0.0-0'])\n",
    "    test['OsBuildLab'] = test['OsBuildLab'].fillna('0.0.0.0.0-0')\n",
    "    \n",
    "    def split_features(df):\n",
    "        \n",
    "        def split(x, pos):\n",
    "            try:\n",
    "                return x.split('.')[pos]\n",
    "            except:\n",
    "                return np.nan\n",
    "            \n",
    "        df['EngineVersion_2'] = df['EngineVersion'].apply(lambda x: split(x, 2)).astype('category')\n",
    "        df['EngineVersion_3'] = df['EngineVersion'].apply(lambda x: split(x, 3)).astype('category')\n",
    "        \n",
    "        df['previous_EngineVersion_2'] = df['previous_EngineVersion'].apply(lambda x: split(x, 2)).astype('category')\n",
    "        df['previous_EngineVersion_3'] = df['previous_EngineVersion'].apply(lambda x: split(x, 3)).astype('category')\n",
    "\n",
    "        df['AppVersion_1'] = df['AppVersion'].apply(lambda x: split(x, 1)).astype('category')\n",
    "        df['AppVersion_2'] = df['AppVersion'].apply(lambda x: split(x, 2)).astype('category')\n",
    "        df['AppVersion_3'] = df['AppVersion'].apply(lambda x: split(x, 3)).astype('category')\n",
    "        \n",
    "        df['previous_AppVersion_1'] = df['previous_AppVersion'].apply(lambda x: split(x, 1)).astype('category')\n",
    "        df['previous_AppVersion_2'] = df['previous_AppVersion'].apply(lambda x: split(x, 2)).astype('category')\n",
    "        df['previous_AppVersion_3'] = df['previous_AppVersion'].apply(lambda x: split(x, 3)).astype('category')\n",
    "\n",
    "        df['AvSigVersion_0'] = df['AvSigVersion'].apply(lambda x: split(x, 0)).astype('category')\n",
    "        df['AvSigVersion_1'] = df['AvSigVersion'].apply(lambda x: split(x, 1)).astype('category')\n",
    "        df['AvSigVersion_2'] = df['AvSigVersion'].apply(lambda x: split(x, 2)).astype('category')\n",
    "        \n",
    "        df['previous_AvSigVersion_0'] = df['previous_AvSigVersion'].apply(lambda x: split(x, 0)).astype('category')\n",
    "        df['previous_AvSigVersion_1'] = df['previous_AvSigVersion'].apply(lambda x: split(x, 1)).astype('category')\n",
    "        df['previous_AvSigVersion_2'] = df['previous_AvSigVersion'].apply(lambda x: split(x, 2)).astype('category')\n",
    "\n",
    "        df['OsBuildLab_0'] = df['OsBuildLab'].apply(lambda x: split(x, 0)).astype('category')\n",
    "        df['OsBuildLab_1'] = df['OsBuildLab'].apply(lambda x: split(x, 1)).astype('category')\n",
    "        df['OsBuildLab_2'] = df['OsBuildLab'].apply(lambda x: split(x, 2)).astype('category')\n",
    "        df['OsBuildLab_3'] = df['OsBuildLab'].apply(lambda x: split(x, 3)).astype('category')\n",
    "        # df['OsBuildLab_40'] = df['OsBuildLab'].apply(lambda x: x.split('.')[4].split('-')[0]).astype('category')\n",
    "        # df['OsBuildLab_41'] = df['OsBuildLab'].apply(lambda x: x.split('.')[4].split('-')[1]).astype('category')\n",
    "\n",
    "        df['Census_OSVersion_0'] = df['Census_OSVersion'].apply(lambda x: split(x, 0)).astype('category')\n",
    "        df['Census_OSVersion_1'] = df['Census_OSVersion'].apply(lambda x: split(x, 1)).astype('category')\n",
    "        df['Census_OSVersion_2'] = df['Census_OSVersion'].apply(lambda x: split(x, 2)).astype('category')\n",
    "        df['Census_OSVersion_3'] = df['Census_OSVersion'].apply(lambda x: split(x, 3)).astype('category')\n",
    "        \n",
    "        df['previous_Census_OSVersion_0'] = df['previous_Census_OSVersion'].apply(lambda x: split(x, 0)).astype('category')\n",
    "        df['previous_Census_OSVersion_1'] = df['previous_Census_OSVersion'].apply(lambda x: split(x, 1)).astype('category')\n",
    "        df['previous_Census_OSVersion_2'] = df['previous_Census_OSVersion'].apply(lambda x: split(x, 2)).astype('category')\n",
    "        df['previous_Census_OSVersion_3'] = df['previous_Census_OSVersion'].apply(lambda x: split(x, 3)).astype('category')\n",
    "        \n",
    "        def new_fe_20190211(df):\n",
    "            df.loc[df['Census_InternalBatteryNumberOfCharges']>500, 'Census_InternalBatteryNumberOfCharges'] = np.nan\n",
    "            df['PEAA'] = df['ProductName'].astype(str) + '_' + df['EngineVersion'].astype(str) + '_' + df['AppVersion'].astype(str) + '_' + df['AvSigVersion'].astype(str)\n",
    "            df['Country_City'] = df['CountryIdentifier'].astype(str) + '_' + df['CityIdentifier'].astype(str) + '_' + df['Census_OSInstallLanguageIdentifier'].astype(str)\n",
    "            # df['SVT_vs_PDTC'] = np.round(df['Census_SystemVolumeTotalCapacity'].astype(float) / df['Census_PrimaryDiskTotalCapacity'].astype(float), 2)\n",
    "            # df['SVT_vs_PDTC'] = df['SVT_vs_PDTC'].astype('category')\n",
    "            return df\n",
    "        \n",
    "        df = new_fe_20190211(df)\n",
    "        \n",
    "        return df\n",
    "        \n",
    "    train, test = split_features(train), split_features(test)\n",
    "    gc.collect()\n",
    "    \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:17<00:00,  4.25s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 26/26 [03:35<00:00,  8.28s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:15<00:00,  3.85s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 26/26 [03:14<00:00,  7.49s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_cols = ['IsProtected', 'Firewall', 'SmartScreen', 'HasTpm', 'SMode']\n",
    "\n",
    "def generate_combos(elements):\n",
    "    output = []\n",
    "    for i in range(2, len(elements)+1):\n",
    "        output += list(itertools.combinations(elements, i))\n",
    "    return output\n",
    "\n",
    "def combine_binary(df):\n",
    "    df['combined_all_binary_cols'] = df[binary_cols[0]].astype(str)\n",
    "    for idx in tqdm(range(1, len(binary_cols))):\n",
    "        df['combined_all_binary_cols'] += '_' + df[binary_cols[idx]].astype(str)\n",
    "        gc.collect()\n",
    "\n",
    "    _all_binary_cols_combo = [list(ele) for ele in generate_combos(binary_cols)]\n",
    "    for combo in tqdm(_all_binary_cols_combo):\n",
    "        _new_name = 'c_' + '_'.join(combo)\n",
    "        _tmp_series = df[combo[0]].astype(str)\n",
    "        for i in range(1, len(combo)):\n",
    "            _tmp_series += df[combo[i]].astype(str)\n",
    "\n",
    "        df[_new_name] = _tmp_series\n",
    "        del _tmp_series\n",
    "        gc.collect()\n",
    "\n",
    "    return df\n",
    "\n",
    "train, test = combine_binary(train), combine_binary(test)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8921483, 151) (7853253, 150)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test = preprocess(train, test)\n",
    "print(train.shape, test.shape)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transform all features to category.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Transform all features to category.\\n')\n",
    "\n",
    "def fe(train, test, vars_to_skip=['HasDetections', 'MachineIdentifier']):\n",
    "    for usecol in tqdm(train.columns.tolist(), total=train.shape[1]-len(vars_to_skip)):\n",
    "        if usecol in vars_to_skip:\n",
    "            print('Skip {}'.format(usecol))\n",
    "            continue\n",
    "        else:\n",
    "            train[usecol] = train[usecol].astype('str')\n",
    "            test[usecol] = test[usecol].astype('str')\n",
    "\n",
    "#             #Fit LabelEncoder\n",
    "#             le = LabelEncoder().fit(\n",
    "#                     np.unique(train[usecol].unique().tolist()+\n",
    "#                               test[usecol].unique().tolist()))\n",
    "\n",
    "#             #At the end 0 will be used for dropped values\n",
    "#             train[usecol] = le.transform(train[usecol])+1\n",
    "#             test[usecol]  = le.transform(test[usecol])+1\n",
    "            \n",
    "            # To numerics:\n",
    "            test[usecol], indexer = pd.factorize(test[usecol])\n",
    "            train[usecol] = indexer.get_indexer(train[usecol])\n",
    "            \n",
    "            test[usecol] += 1\n",
    "            train[usecol] += 1\n",
    "\n",
    "            agg_tr = (train\n",
    "                      .groupby([usecol])\n",
    "                      .aggregate({'MachineIdentifier':'count'})\n",
    "                      .reset_index()\n",
    "                      .rename({'MachineIdentifier':'Train'}, axis=1))\n",
    "            agg_te = (test\n",
    "                      .groupby([usecol])\n",
    "                      .aggregate({'MachineIdentifier':'count'})\n",
    "                      .reset_index()\n",
    "                      .rename({'MachineIdentifier':'Test'}, axis=1))\n",
    "\n",
    "            agg = pd.merge(agg_tr, agg_te, on=usecol, how='outer').replace(np.nan, 0)\n",
    "            #Select values with more than threshold\n",
    "            agg = agg[(agg['Train'] > 100)].reset_index(drop=True)\n",
    "            agg['Total'] = agg['Train'] + agg['Test']\n",
    "            #Drop unbalanced values\n",
    "            agg = agg[(agg['Train'] / agg['Total'] > 0.2) & (agg['Train'] / agg['Total'] < 0.8)]\n",
    "            agg[usecol+'Copy'] = agg[usecol]\n",
    "\n",
    "            train[usecol] = (pd.merge(train[[usecol]], \n",
    "                                      agg[[usecol, usecol+'Copy']], \n",
    "                                      on=usecol, how='left')[usecol+'Copy']\n",
    "                             .replace(np.nan, 0).astype('int').astype('category'))\n",
    "\n",
    "            test[usecol]  = (pd.merge(test[[usecol]], \n",
    "                                      agg[[usecol, usecol+'Copy']], \n",
    "                                      on=usecol, how='left')[usecol+'Copy']\n",
    "                             .replace(np.nan, 0).astype('int').astype('category'))\n",
    "\n",
    "            del agg_tr, agg_te, agg, usecol\n",
    "            gc.collect()\n",
    "    \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                          | 0/149 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skip MachineIdentifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Exception in thread Thread-16:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\xiaowei.li\\appdata\\local\\continuum\\anaconda3\\envs\\myvirtualpythonenv\\lib\\threading.py\", line 914, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\users\\xiaowei.li\\appdata\\local\\continuum\\anaconda3\\envs\\myvirtualpythonenv\\lib\\site-packages\\tqdm\\_monitor.py\", line 62, in run\n",
      "    for instance in self.tqdm_cls._instances:\n",
      "  File \"c:\\users\\xiaowei.li\\appdata\\local\\continuum\\anaconda3\\envs\\myvirtualpythonenv\\lib\\_weakrefset.py\", line 60, in __iter__\n",
      "    for itemref in self.data:\n",
      "RuntimeError: Set changed size during iteration\n",
      "\n",
      " 55%|████████████████████████████████████████████▌                                    | 82/149 [30:25<24:51, 22.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skip HasDetections\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "151it [1:06:29, 26.42s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test = fe(train, test)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = np.array(train['HasDetections'])\n",
    "del train['HasDetections'], train['MachineIdentifier'], test['MachineIdentifier']\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 90/90 [02:58<00:00,  1.98s/it]\n"
     ]
    }
   ],
   "source": [
    "#Fit OneHotEncoder\n",
    "ohe = OneHotEncoder(n_values='auto', sparse=True, dtype='uint8').fit(train)\n",
    "\n",
    "#Transform data using small groups to reduce memory usage\n",
    "m = 100000\n",
    "train = vstack([ohe.transform(train[i*m:(i+1)*m]) for i in tqdm(range(train.shape[0] // m + 1))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = csr_matrix(train, dtype='float32')\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_train = lgb.Dataset(train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'max_depth':-1,\n",
    "    'num_leaves':2**11-1,\n",
    "    'colsample_bytree':0.35,\n",
    "    'objective':'binary',\n",
    "    'n_jobs':-1,\n",
    "    'learning_rate':0.05\n",
    "}\n",
    "\n",
    "cv_score = lgb.cv(params=params, train_set=lgb_train, num_boost_round=30000, metrics='auc', early_stopping_rounds=75, seed=7)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
