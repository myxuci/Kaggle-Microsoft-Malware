{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\xiaowei.li\\appdata\\local\\continuum\\anaconda3\\envs\\myvirtualpythonenv\\lib\\importlib\\_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-3eb84dd08c93>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLogisticRegressionCV\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mcatboost\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCatBoostClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtqdm_notebook\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moffline\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpy\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\xiaowei.li\\appdata\\local\\continuum\\anaconda3\\envs\\myvirtualpythonenv\\lib\\site-packages\\catboost\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mFeaturesData\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mEFstrType\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCatBoost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCatBoostClassifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCatBoostRegressor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCatboostError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msum_models\u001b[0m  \u001b[1;31m# noqa\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mVERSION\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m__version__\u001b[0m  \u001b[1;31m# noqa\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0m__all__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'FeaturesData'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'EFstrType'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Pool'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'CatBoost'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'CatBoostClassifier'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'CatBoostRegressor'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'CatboostError'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'cv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'train'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'sum_models'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\xiaowei.li\\appdata\\local\\continuum\\anaconda3\\envs\\myvirtualpythonenv\\lib\\site-packages\\catboost\\core.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m \u001b[0m_catboost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_catboost_bin_module\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m \u001b[0m_PoolBase\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_catboost\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_PoolBase\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[0m_CatBoost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_catboost\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_CatBoost\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\xiaowei.li\\appdata\\local\\continuum\\anaconda3\\envs\\myvirtualpythonenv\\lib\\site-packages\\catboost\\core.py\u001b[0m in \u001b[0;36mget_catboost_bin_module\u001b[1;34m()\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mso_path\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mso_paths\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m             \u001b[0mloaded_catboost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_dynamic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'_catboost'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mso_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m             \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'catboost._catboost'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloaded_catboost\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mloaded_catboost\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\xiaowei.li\\appdata\\local\\continuum\\anaconda3\\envs\\myvirtualpythonenv\\lib\\imp.py\u001b[0m in \u001b[0;36mload_dynamic\u001b[1;34m(name, path, file)\u001b[0m\n\u001b[0;32m    340\u001b[0m         spec = importlib.machinery.ModuleSpec(\n\u001b[0;32m    341\u001b[0m             name=name, loader=loader, origin=path)\n\u001b[1;32m--> 342\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\xiaowei.li\\appdata\\local\\continuum\\anaconda3\\envs\\myvirtualpythonenv\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36mparent\u001b[1;34m(self)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#libraries\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from numba import jit\n",
    "import time\n",
    "import datetime\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from numba import jit\n",
    "from utils import *\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error, roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "import gc\n",
    "from catboost import CatBoostClassifier\n",
    "from tqdm import tqdm_notebook\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "# from XGBoost.XGBoost_ToolBox_ver3 import *\n",
    "from LightGBM.LightGBM_ToolBox_ver2 import *\n",
    "# from DataProcessingTools.CatVarTools import *\n",
    "from category_encoders.target_encoder import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(filename='log.txt',level=logging.DEBUG, format='%(asctime)s %(message)s')\n",
    "\n",
    "pd.set_option('max_colwidth', 500)\n",
    "pd.set_option('max_columns', 500)\n",
    "pd.set_option('max_rows', 500)\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = pd.read_pickle('./Data/train_only_test_eles.pkl')\n",
    "# test = pd.read_pickle('./Data/test.pkl')\n",
    "# gc.collect()\n",
    "\n",
    "with open('dtypes.json', 'r') as file:\n",
    "    dtypes = json.load(file)\n",
    "    \n",
    "    numerics = ['int8', 'int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    numerical_columns = [c for c,v in dtypes.items() if v in numerics]\n",
    "    categorical_columns = [c for c,v in dtypes.items() if v not in numerics]\n",
    "    \n",
    "    train = pd.read_csv('./Data/train.csv', dtype=dtypes) \n",
    "\n",
    "    # To-be truncated:\n",
    "    test = pd.read_csv('./Data/test.csv', dtype=dtypes)\n",
    "    test.loc[6529507, 'OsBuildLab'] = '17134.1.amd64fre.rs4_release.180410-1804'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load AvSigVersion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with timer('IMPORT TIMESTAMP DICTIONARY'):\n",
    "    # IMPORT TIMESTAMP DICTIONARY\n",
    "    datedict = np.load('./Data/AvSigVersionTimestamps.npy')\n",
    "    datedict = datedict[()]\n",
    "    # ADD TIMESTAMPS\n",
    "    train['Date'] = train['AvSigVersion'].map(datedict)\n",
    "    test['Date'] = test['AvSigVersion'].map(datedict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with timer():\n",
    "    print(train[train['Date']>='2018-09-01'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Proc data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with timer():\n",
    "    # stats = []\n",
    "    # for col in train.columns:\n",
    "    #     stats.append((col, train[col].nunique(), train[col].isnull().sum() * 100 / train.shape[0], train[col].value_counts(normalize=True, dropna=False).values[0] * 100, train[col].dtype))\n",
    "\n",
    "    # stats_df = pd.DataFrame(stats, columns=['Feature', 'Unique_values', 'Percentage of missing values', 'Percentage of values in the biggest category', 'type'])\n",
    "    # stats_df.sort_values('Percentage of missing values', ascending=False)\n",
    "\n",
    "    # stats_df.to_csv('./sln/feature_selection.csv', index=False)\n",
    "\n",
    "    stats_df = pd.read_csv('./sln/feature_selection.csv')\n",
    "    # stats_df.head(3)\n",
    "\n",
    "    _threshold = 0.9\n",
    "\n",
    "    good_cols = train.columns.tolist()\n",
    "    for col in train.columns:\n",
    "        rate = train[col].value_counts(normalize=True, dropna=False).values[0]\n",
    "        if rate > _threshold:\n",
    "            good_cols.remove(col)\n",
    "\n",
    "\n",
    "    print('Removed {} cols...'.format(train.shape[1] - len(good_cols)))\n",
    "\n",
    "    train = train[good_cols]\n",
    "    test['HasDetections'] = -999\n",
    "    test = test[good_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/youhanlee/my-eda-i-want-to-see-all\n",
    "# grouping battary types by name\n",
    "def group_battery(x):\n",
    "    x = x.lower()\n",
    "    if 'li' in x:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "with timer():    \n",
    "    train['Census_InternalBatteryType'] = train['Census_InternalBatteryType'].astype(str).apply(group_battery)\n",
    "    test['Census_InternalBatteryType'] = test['Census_InternalBatteryType'].astype(str).apply(group_battery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_edition(x):\n",
    "    x = x.lower()\n",
    "    if 'core' in x:\n",
    "        return 'Core'\n",
    "    elif 'pro' in x:\n",
    "        return 'pro'\n",
    "    elif 'enterprise' in x:\n",
    "        return 'Enterprise'\n",
    "    elif 'server' in x:\n",
    "        return 'Server'\n",
    "    elif 'home' in x:\n",
    "        return 'Home'\n",
    "    elif 'education' in x:\n",
    "        return 'Education'\n",
    "    elif 'cloud' in x:\n",
    "        return 'Cloud'\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "with timer():\n",
    "    train['Census_OSEdition'] = train['Census_OSEdition'].astype(str)\n",
    "    test['Census_OSEdition'] = test['Census_OSEdition'].astype(str)\n",
    "    train['Census_OSEdition'] = train['Census_OSEdition'].apply(rename_edition)\n",
    "    test['Census_OSEdition'] = test['Census_OSEdition'].apply(rename_edition)\n",
    "    train['Census_OSEdition'] = train['Census_OSEdition'].astype('category')\n",
    "    test['Census_OSEdition'] = test['Census_OSEdition'].astype('category')\n",
    "\n",
    "    train['Census_OSSkuName'] = train['Census_OSSkuName'].astype(str)\n",
    "    test['Census_OSSkuName'] = test['Census_OSSkuName'].astype(str)\n",
    "    train['Census_OSSkuName'] = train['Census_OSSkuName'].apply(rename_edition)\n",
    "    test['Census_OSSkuName'] = test['Census_OSSkuName'].apply(rename_edition)\n",
    "    train['Census_OSSkuName'] = train['Census_OSSkuName'].astype('category')\n",
    "    test['Census_OSSkuName'] = test['Census_OSSkuName'].astype('category')\n",
    "\n",
    "    train['OsBuildLab'] = train['OsBuildLab'].cat.add_categories(['0.0.0.0.0-0'])\n",
    "    train['OsBuildLab'] = train['OsBuildLab'].fillna('0.0.0.0.0-0')\n",
    "    test['OsBuildLab'] = test['OsBuildLab'].cat.add_categories(['0.0.0.0.0-0'])\n",
    "    test['OsBuildLab'] = test['OsBuildLab'].fillna('0.0.0.0.0-0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Feature engineering...')\n",
    "def agg_(df, target, *args):\n",
    "    \n",
    "    # mean_col_name = '{}_mean_by_{}'.format(target, '_'.join(args))\n",
    "    count_col_name = '{}_count_by_{}'.format(target, '_'.join(args))\n",
    "    nunique_col_name = '{}_nunique_by_{}'.format(target, '_'.join(args))\n",
    "    \n",
    "    tmp = df.groupby(args)[target].agg({nunique_col_name:'nunique', count_col_name:'count'}).reset_index()\n",
    "    \n",
    "    ratio_col_name = '{}_nunique_vs_count_by_{}'.format(target, '_'.join(args))\n",
    "    tmp[ratio_col_name] = tmp[nunique_col_name] / tmp[count_col_name]\n",
    "    df = pd.merge(df, tmp, on=args, how='left')\n",
    "    \n",
    "    return df, [count_col_name, nunique_col_name, ratio_col_name]\n",
    "\n",
    "@jit\n",
    "def target_encoding(df, cols, target_col):\n",
    "    if not isinstance(cols, list):\n",
    "        cols = [cols]\n",
    "        \n",
    "    encoder = TargetEncoder(cols=cols).fit(df.drop(target_col, axis=1), df[target_col])\n",
    "    df = encoder.transform(df.drop(target_col, axis=1))\n",
    "    return df\n",
    "\n",
    "def replace_outliers(dataframe, col, upper_limit=None, lower_limit=None, replacement=np.nan):\n",
    "    if upper_limit is not None:\n",
    "        dataframe.loc[dataframe[col]<upper_limit, col] = replacement\n",
    "    elif lower_limit is not None:\n",
    "        dataframe.loc[dataframe[col]>lower_limit, col] = replacement\n",
    "    \n",
    "    return dataframe\n",
    "\n",
    "def replace_new_names(dataframe, col, old_name, new_name):\n",
    "    dataframe.loc[dataframe[col]==old_name, col] = new_name\n",
    "    return dataframe\n",
    "\n",
    "def fe(df):\n",
    "    # Add on 2019-01-30:\n",
    "    # Remove some outliers:\n",
    "#     ['MachineIdentifier', 'AvSigVersion', 'AVProductStatesIdentifier', 'CityIdentifier', 'Census_OEMNameIdentifier', \\\n",
    "#      'Census_OEMModelIdentifier', 'Census_ProcessorModelIdentifier', 'Census_PrimaryDiskTotalCapacity', 'Census_SystemVolumeTotalCapacity', 'Census_TotalPhysicalRAM', 'Census_InternalPrimaryDisplayResolutionHorizontal', 'Census_InternalPrimaryDisplayResolutionVertical', 'Census_InternalBatteryNumberOfCharges', 'Census_FirmwareVersionIdentifier', 'AvSigVersion_2', 'EngineVersion_AppVersion_AvSigVersion', \\\n",
    "#      'primary_drive_c_ratio', 'non_primary_drive_MB', 'aspect_ratio', 'monitor_dims', 'Screen_Area', 'ram_per_processor', 'new_num_0', 'new_num_1']\n",
    "#     for col in ['AvSigVersion', 'AVProductStatesIdentifier', 'CityIdentifier', 'Census_OEMNameIdentifier', \\\n",
    "#                 'Census_OEMModelIdentifier', 'Census_ProcessorModelIdentifier', 'Census_PrimaryDiskTotalCapacity', 'Census_SystemVolumeTotalCapacity', \\\n",
    "#                 'Census_TotalPhysicalRAM']:\n",
    "#         pass\n",
    "    \n",
    "    # Agg features:\n",
    "    num_vars = []\n",
    "    df, cols = agg_(df, 'Census_OSInstallLanguageIdentifier', 'CountryIdentifier')\n",
    "    num_vars += cols\n",
    "    \n",
    "    df, cols = agg_(df, 'Census_OSInstallLanguageIdentifier', 'CountryIdentifier', 'CityIdentifier')\n",
    "    num_vars += cols\n",
    "    \n",
    "    df, cols = agg_(df, 'Census_FirmwareManufacturerIdentifier', 'CountryIdentifier')\n",
    "    num_vars += cols\n",
    "    \n",
    "    df, cols = agg_(df, 'Census_FirmwareManufacturerIdentifier', 'CountryIdentifier', 'CityIdentifier')\n",
    "    num_vars += cols\n",
    "    \n",
    "    df, cols = agg_(df, 'Census_OEMModelIdentifier', 'CountryIdentifier')\n",
    "    num_vars += cols\n",
    "    \n",
    "    df, cols = agg_(df, 'Census_OEMModelIdentifier', 'CountryIdentifier', 'CityIdentifier')\n",
    "    num_vars += cols\n",
    "    \n",
    "    df, cols = agg_(df, 'AvSigVersion', 'CountryIdentifier')\n",
    "    num_vars += cols\n",
    "    \n",
    "    df, cols = agg_(df, 'AvSigVersion', 'CountryIdentifier', 'CityIdentifier')\n",
    "    num_vars += cols\n",
    "    \n",
    "    df, cols = agg_(df, 'Census_ProcessorModelIdentifier', 'CountryIdentifier')\n",
    "    num_vars += cols\n",
    "    \n",
    "    df, cols = agg_(df, 'Census_ProcessorModelIdentifier', 'CountryIdentifier', 'CityIdentifier')\n",
    "    num_vars += cols\n",
    "    \n",
    "    df, cols = agg_(df, 'AVProductStatesIdentifier', 'CountryIdentifier')\n",
    "    num_vars += cols\n",
    "    \n",
    "    df, cols = agg_(df, 'AVProductStatesIdentifier', 'CountryIdentifier', 'CityIdentifier')\n",
    "    num_vars += cols\n",
    "    \n",
    "    df['EngineVersion_2'] = df['EngineVersion'].apply(lambda x: x.split('.')[2]).astype('category')\n",
    "    df['EngineVersion_3'] = df['EngineVersion'].apply(lambda x: x.split('.')[3]).astype('category')\n",
    "\n",
    "    df['AppVersion_1'] = df['AppVersion'].apply(lambda x: x.split('.')[1]).astype('category')\n",
    "    df['AppVersion_2'] = df['AppVersion'].apply(lambda x: x.split('.')[2]).astype('category')\n",
    "    df['AppVersion_3'] = df['AppVersion'].apply(lambda x: x.split('.')[3]).astype('category')\n",
    "\n",
    "    df['AvSigVersion_0'] = df['AvSigVersion'].apply(lambda x: x.split('.')[0]).astype('category')\n",
    "    df['AvSigVersion_1'] = df['AvSigVersion'].apply(lambda x: x.split('.')[1]).astype('category')\n",
    "    df['AvSigVersion_2'] = df['AvSigVersion'].apply(lambda x: x.split('.')[2]).astype('category')\n",
    "\n",
    "    df['OsBuildLab_0'] = df['OsBuildLab'].apply(lambda x: x.split('.')[0]).astype('category')\n",
    "    df['OsBuildLab_1'] = df['OsBuildLab'].apply(lambda x: x.split('.')[1]).astype('category')\n",
    "    df['OsBuildLab_2'] = df['OsBuildLab'].apply(lambda x: x.split('.')[2]).astype('category')\n",
    "    df['OsBuildLab_3'] = df['OsBuildLab'].apply(lambda x: x.split('.')[3]).astype('category')\n",
    "    # df['OsBuildLab_40'] = df['OsBuildLab'].apply(lambda x: x.split('.')[4].split('-')[0]).astype('category')\n",
    "    # df['OsBuildLab_41'] = df['OsBuildLab'].apply(lambda x: x.split('.')[4].split('-')[1]).astype('category')\n",
    "\n",
    "    df['Census_OSVersion_0'] = df['Census_OSVersion'].apply(lambda x: x.split('.')[0]).astype('category')\n",
    "    df['Census_OSVersion_1'] = df['Census_OSVersion'].apply(lambda x: x.split('.')[1]).astype('category')\n",
    "    df['Census_OSVersion_2'] = df['Census_OSVersion'].apply(lambda x: x.split('.')[2]).astype('category')\n",
    "    df['Census_OSVersion_3'] = df['Census_OSVersion'].apply(lambda x: x.split('.')[3]).astype('category')\n",
    "    \n",
    "    # My stuff:\n",
    "    df['EngineVersion_AppVersion_AvSigVersion'] = df['EngineVersion'].astype(str) + '_' + df['AppVersion'].astype(str) + '_' + df['AvSigVersion'].astype(str)\n",
    "    \n",
    "    # Update data:\n",
    "#     df = replace_new_names(df, col='Census_ChassisTypeName', old_name='Laptop', new_name='Notebook')\n",
    "#     df = replace_new_names(df, col='Census_ChassisTypeName', old_name='AllinOne', new_name='Desktop')\n",
    "#     df = replace_new_names(df, col='Census_ChassisTypeName', old_name='Detachable', new_name='Notebook')\n",
    "#     df = replace_new_names(df, col='Census_ChassisTypeName', old_name='MiniTower', new_name='Desktop')\n",
    "#     df = replace_new_names(df, col='Census_ChassisTypeName', old_name='LowProfileDesktop', new_name='Desktop')\n",
    "#     df = replace_new_names(df, col='Census_ChassisTypeName', old_name='Convertible', new_name='Notebook')\n",
    "#     df = replace_new_names(df, col='Census_PowerPlatformRoleName', old_name='UNKNOWN', new_name=np.nan)\n",
    "#     df = replace_new_names(df, col='Census_PowerPlatformRoleName', old_name='Unspecified', new_name=np.nan)\n",
    "#     df = replace_new_names(df, col='SmartScreen', old_name='unspecified', new_name=np.nan)\n",
    "\n",
    "    df = replace_new_names(df, col='AvSigVersion', old_name='0.0.0.0', new_name=np.nan)\n",
    "    # df = replace_new_names(df, col='AvSigVersion_2', old_name=0, new_name=np.nan)\n",
    "    # df = replace_new_names(df, col='AvSigVersion_3', old_name=0, new_name=np.nan)\n",
    "    \n",
    "    # Set battery cycle threshold to be 500:\n",
    "    df.loc[df['Census_InternalBatteryNumberOfCharges']>500, 'Census_InternalBatteryNumberOfCharges'] = np.nan\n",
    "    df.loc[df['Census_PrimaryDiskTypeName']=='UNKNOWN', 'Census_PrimaryDiskTypeName'] = np.nan\n",
    "    df.loc[df['Census_PrimaryDiskTypeName']=='Unspecified', 'Census_PrimaryDiskTypeName'] = np.nan\n",
    "\n",
    "    # https://www.kaggle.com/adityaecdrid/simple-feature-engineering-xd\n",
    "    df['primary_drive_c_ratio'] = df['Census_SystemVolumeTotalCapacity']/ df['Census_PrimaryDiskTotalCapacity']\n",
    "    df['non_primary_drive_MB'] = df['Census_PrimaryDiskTotalCapacity'] - df['Census_SystemVolumeTotalCapacity']\n",
    "\n",
    "    df['aspect_ratio'] = df['Census_InternalPrimaryDisplayResolutionHorizontal']/ df['Census_InternalPrimaryDisplayResolutionVertical']\n",
    "\n",
    "    df['monitor_dims'] = df['Census_InternalPrimaryDisplayResolutionHorizontal'].astype(str) + '*' + df['Census_InternalPrimaryDisplayResolutionVertical'].astype('str')\n",
    "    df['monitor_dims'] = df['monitor_dims'].astype('category')\n",
    "\n",
    "    df['dpi'] = ((df['Census_InternalPrimaryDisplayResolutionHorizontal']**2 + df['Census_InternalPrimaryDisplayResolutionVertical']**2)**.5)/(df['Census_InternalPrimaryDiagonalDisplaySizeInInches'])\n",
    "\n",
    "    df['dpi_square'] = df['dpi'] ** 2\n",
    "\n",
    "    df['MegaPixels'] = (df['Census_InternalPrimaryDisplayResolutionHorizontal'] * df['Census_InternalPrimaryDisplayResolutionVertical'])/1e6\n",
    "\n",
    "    df['Screen_Area'] = (df['aspect_ratio']* (df['Census_InternalPrimaryDiagonalDisplaySizeInInches']**2))/(df['aspect_ratio']**2 + 1)\n",
    "\n",
    "    df['ram_per_processor'] = df['Census_TotalPhysicalRAM']/ df['Census_ProcessorCoreCount']\n",
    "\n",
    "    df['new_num_0'] = df['Census_InternalPrimaryDiagonalDisplaySizeInInches'] / df['Census_ProcessorCoreCount']\n",
    "\n",
    "    df['new_num_1'] = df['Census_ProcessorCoreCount'] * df['Census_InternalPrimaryDiagonalDisplaySizeInInches']\n",
    "    \n",
    "#     df['Census_IsFlightingInternal'] = df['Census_IsFlightingInternal'].fillna(1)\n",
    "#     df['Census_ThresholdOptIn'] = df['Census_ThresholdOptIn'].fillna(1)\n",
    "#     df['Census_IsWIMBootEnabled'] = df['Census_IsWIMBootEnabled'].fillna(1)\n",
    "#     df['Wdft_IsGamer'] = df['Wdft_IsGamer'].fillna(0)\n",
    "    \n",
    "#     target_col = 'HasDetections'\n",
    "#     hcc_col = [ele for ele in df.columns if df[ele].nunique()>=500]\n",
    "# #     te = TargetEncoder(verbose=1, cols=hcc_col).fit(df.drop(target_col, axis=1), df[target_col])\n",
    "# #     df = te.transform(df.drop(target_col, axis=1))\n",
    "#     for col in tqdm(hcc_col):\n",
    "#         df = target_encoding(df, col, target_col)\n",
    "    \n",
    "    return df, num_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with timer('Feature engineering of training data'):\n",
    "    train, num_vars = fe(train)\n",
    "\n",
    "with timer('Feature engineering of testing data'):\n",
    "    test, num_vars = fe(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = [\n",
    "    'Census_InternalBatteryNumberOfCharges',\n",
    "    'primary_drive_c_ratio',\n",
    "    'non_primary_drive_MB' ,\n",
    "    'Census_SystemVolumeTotalCapacity',\n",
    "    'Census_PrimaryDiskTotalCapacity',\n",
    "    'Census_InternalPrimaryDiagonalDisplaySizeInInches',\n",
    "    'new_num_0',\n",
    "    'new_num_1',\n",
    "    'Screen_Area',\n",
    "    'ram_per_processor'\n",
    "]\n",
    "\n",
    "numeric_cols += num_vars\n",
    "\n",
    "cols_to_skip = [\n",
    "    'MachineIdentifier',\n",
    "    'HasDetections',\n",
    "    'Date' # For time-series splitting...\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with timer('Add some additional features'):\n",
    "    more_cat_cols = []\n",
    "    add_cat_feats = [\n",
    "         'Census_OSBuildRevision',\n",
    "         'OsBuildLab',\n",
    "         'SmartScreen',\n",
    "        'AVProductsInstalled'\n",
    "    ]\n",
    "\n",
    "    for col1 in add_cat_feats:\n",
    "        for col2 in add_cat_feats:\n",
    "            if col1 != col2:\n",
    "                train[col1 + '__' + col2] = train[col1].astype(str) + '_' + train[col2].astype(str)\n",
    "                train[col1 + '__' + col2] = train[col1 + '__' + col2].astype('category')\n",
    "\n",
    "                test[col1 + '__' + col2] = test[col1].astype(str) + '_' + test[col2].astype(str)\n",
    "                test[col1 + '__' + col2] = test[col1 + '__' + col2].astype('category')\n",
    "                more_cat_cols.append(col1 + '__' + col2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with timer('Elminating the unique elements only existing in training data, change them to None.'):\n",
    "    vars_to_skip = cols_to_skip + numeric_cols\n",
    "    train = change_unique_ele_in_train(train, test, vars_to_skip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import LabelEncoder\n",
    "def my_label_encoder(data):\n",
    "    assert isinstance(data, list), TypeError('Must be list.')\n",
    "    ele_map = {}\n",
    "    _pnt = 0\n",
    "    output = []\n",
    "    for ele in data:\n",
    "        if not pd.isnull(ele): # Skip nan.\n",
    "            if ele not in ele_map:\n",
    "                ele_map[ele] = _pnt\n",
    "                output.append(_pnt)\n",
    "                _pnt += 1\n",
    "            else:\n",
    "                output.append(ele_map[ele])\n",
    "        else:\n",
    "            output.append(ele)\n",
    "                \n",
    "    return ele_map, output\n",
    "\n",
    "def my_label_encoder2(train, test, col, unique_ele_list):\n",
    "    assert isinstance(unique_ele_list, list), TypeError('Must be list.')\n",
    "    assert len(np.unique(unique_ele_list)) == len(unique_ele_list), 'Duplicated elements exists in input list.'\n",
    "    \n",
    "    ele_map = {}\n",
    "    for idx, unique_ele in enumerate(unique_ele_list):\n",
    "        if not pd.isnull(unique_ele): # Skip nan.\n",
    "            if unique_ele not in ele_map:\n",
    "                ele_map[unique_ele] = idx\n",
    "    \n",
    "    def ele2num(X):\n",
    "        try:\n",
    "            if not pd.isnull(X):\n",
    "                return ele_map[X]\n",
    "            else:\n",
    "                return np.nan\n",
    "        except Exception as e:\n",
    "            print(X)\n",
    "            return np.nan\n",
    "    \n",
    "    # encoded_train = train[col].apply(lambda X: ele_map[X] if not pd.isnull(X) else np.nan)\n",
    "    # encoded_test = test[col].apply(lambda X: ele_map[X] if not pd.isnull(X) else np.nan)\n",
    "    \n",
    "    encoded_train = train[col].apply(ele2num)\n",
    "    encoded_test = test[col].apply(ele2num)\n",
    "    \n",
    "    return encoded_train, encoded_test, ele_map\n",
    "\n",
    "def cat_vars_encoding(train, test, numeric_cols, cols_to_skip, one_hot=5, verbose=False):\n",
    "    cols_to_skip = numeric_cols + cols_to_skip\n",
    "    processed_cols = []\n",
    "    for col in train.columns.tolist():\n",
    "        if col in cols_to_skip:\n",
    "            if verbose:\n",
    "                print('Pass {}...'.format(col))\n",
    "            continue\n",
    "        elif 'LE' in col: # Some cols already encoded.\n",
    "            continue\n",
    "        elif 'OHE' in col:\n",
    "            continue\n",
    "        elif 'ME' in col:\n",
    "            continue\n",
    "        else:\n",
    "            processed_cols.append(cols)\n",
    "            unique_ele_list = np.unique(train[col].unique().tolist() + test[col].unique().tolist()).tolist()\n",
    "            if len(unique_ele_list) > one_hot:\n",
    "                if verbose:\n",
    "                    print('Label encoding {}...'.format(col))\n",
    "                encoded_train, encoded_test, _ = my_label_encoder2(train, test, col, unique_ele_list)\n",
    "                new_col_name = 'LE_' + col\n",
    "                train[new_col_name] = encoded_train\n",
    "                test[new_col_name] = encoded_test\n",
    "                del encoded_train, encoded_test\n",
    "                gc.collect()\n",
    "            else:\n",
    "                if verbose:\n",
    "                    print('One-hot encoding {}...'.format(col))\n",
    "                _list_to_ohe = train[col].tolist() + test[col].tolist()\n",
    "                ohe_cols = pd.get_dummies(_list_to_ohe, \\\n",
    "                                          prefix='OHE_{}_'.format(col),\\\n",
    "                                          dummy_na=True)\n",
    "                train = pd.concat([train, ohe_cols.iloc[:train.shape[0]]], axis=1)\n",
    "                test = pd.concat([test, ohe_cols.iloc[train.shape[0]:]], axis=1)\n",
    "                del ohe_cols\n",
    "                gc.collect()\n",
    "\n",
    "                \n",
    "            # Drop the old column:\n",
    "            train.drop([col], axis=1, inplace=True)\n",
    "            gc.collect()\n",
    "            test.drop([col], axis=1, inplace=True)\n",
    "            gc.collect()\n",
    "            \n",
    "    return train, test\n",
    "\n",
    "def mean_encoding(train, test, numeric_cols, cols_to_skip, mean_encoding_ele_threshold=1000, \\\n",
    "                  mean_encoding_target='HasDetections', verbose=True):\n",
    "    cols_to_skip = numeric_cols + cols_to_skip\n",
    "    \n",
    "    me_cols = []\n",
    "    for col in train.columns:\n",
    "        if col in vars_to_skip:\n",
    "            print('Skip column of {}...'.format(col))\n",
    "            continue\n",
    "        else:\n",
    "            if verbose:\n",
    "                print('Mean encoding column of {}...'.format(col))\n",
    "            unique_ele_list = np.unique(train[col].unique().tolist() + test[col].unique().tolist()).tolist()\n",
    "            if len(unique_ele_list) > mean_encoding_ele_threshold:\n",
    "                _encoded_train, _encoded_test = target_encode(train[col], test[col], target=mean_encoding_target)\n",
    "                new_col_name = 'ME_' + col\n",
    "                train[new_col_name] = _encoded_train.values.squeeze().tolist()\n",
    "                test[new_col_name] = _encoded_test.values.squeeze().tolist()\n",
    "                me_cols.append(new_col_name)\n",
    "                del _encoded_train, _encoded_test\n",
    "                gc.collect()\n",
    "                \n",
    "    return train, test, me_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with timer('Encoding cat vars'):\n",
    "    gc.collect()\n",
    "    train, test = cat_vars_encoding(train, test, numeric_cols, cols_to_skip, verbose=True)\n",
    "    train, test, me_cols = mean_encoding(train, test, numeric_cols, cols_to_skip, veerbose=True)\n",
    "    numeric_cols += me_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with timer('Some final processing'):\n",
    "    train.drop(['MachineIdentifier'], axis=1, inplace=True)\n",
    "    test.drop(['MachineIdentifier'], axis=1, inplace=True)\n",
    "    gc.collect()\n",
    "    \n",
    "    target_col = 'HasDetections'\n",
    "    cutoff_date = '2018-09-01'\n",
    "    train_X = train[train['Date']>=cutoff_date].drop([target_col], axis=1)\n",
    "    train_y = train[train['Date']>=cutoff_date][target_col]\n",
    "    valid_X = train[train['Date']<cutoff_date].drop([target_col], axis=1)\n",
    "    valid_y = train[train['Date']<cutoff_date][target_col]\n",
    "    gc.collect()\n",
    "    \n",
    "    train_X.drop(['Date'], axis=1, inplace=True)\n",
    "    valid_X.drop(['Date'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cat_vars(df, numeric_cols, cols_to_skip):\n",
    "    cols_to_skip += numeric_cols \n",
    "    \n",
    "    cat_vars = []\n",
    "    for col in df.columns.tolist():\n",
    "        if col in cols_to_skip:\n",
    "            continue\n",
    "        elif 'ME_' in col:\n",
    "            continue\n",
    "        else:\n",
    "            cat_vars.append(col)\n",
    "    \n",
    "    return cat_vars\n",
    "\n",
    "with timer('Cal cat vars'):\n",
    "    cat_vars = get_cat_vars(train, numeric_cols, cols_to_skip)\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Before model training, train data size: {}, test data size: {}'.format(train.shape, test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    del mylight\n",
    "    gc.collect()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "mylight = MyLight(objective='binary')\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res = mylight.lgb_cv(\n",
    "#     train_X=train_X,\n",
    "#     train_y=train_y,\n",
    "#     categorical_feature=cat_vars,\n",
    "#     num_iterations=1000,\n",
    "#     learning_rate=0.05,\n",
    "#     metrics=['auc'],\n",
    "#     nfold=5\n",
    "# )\n",
    "\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mylight.fit(\n",
    "    train_X,\n",
    "    train_y,\n",
    "    valid_X=valid_X,\n",
    "    valid_y=valid_y,\n",
    "    num_iterations=1000,\n",
    "    learning_rate=0.05,\n",
    "    categorical_feature=cat_vars,\n",
    "    eval_metric='auc',\n",
    "    verbose_eval=200,\n",
    "    autosave_ckpt=False\n",
    ")\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
