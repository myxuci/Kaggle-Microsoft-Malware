[02/03/2019 12:23:04 PM (Local Time)] INFO : Start logging...
[02/03/2019 12:23:04 PM (Local Time)] INFO : Update instance booster params to: {'subsample_for_bin': 200000, 'class_weight': None, 'min_split_gain': 0.0, 'subsample': 1.0, 'num_leaves': 31, 'reg_lambda': 0.0, 'n_estimators': 100, 'boosting_type': 'gbdt', 'min_child_samples': 20, 'colsample_bytree': 1.0, 'subsample_freq': 0, 'max_depth': -1, 'reg_alpha': 0.0, 'min_child_weight': 0.001, 'objective': 'regression'}
[02/03/2019 12:27:48 PM (Local Time)] INFO : Initial learning rate: 0.1, adjustable learning rates: [0.1, 0.001, 0.0001, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05]
[02/03/2019 12:27:48 PM (Local Time)] INFO : Randomly split training data into 70% to 30%.
[02/03/2019 12:27:48 PM (Local Time)] INFO : Training data size: (354, 13), validation data size: (152, 13)
[02/03/2019 12:27:48 PM (Local Time)] INFO : Booster parameters: {'subsample_for_bin': 200000, 'class_weight': None, 'min_split_gain': 0.0, 'subsample': 1.0, 'num_leaves': 31, 'reg_lambda': 0.0, 'n_estimators': 100, 'boosting_type': 'gbdt', 'min_child_samples': 20, 'colsample_bytree': 1.0, 'subsample_freq': 0, 'max_depth': -1, 'reg_alpha': 0.0, 'min_child_weight': 0.001, 'objective': 'regression', 'num_iterations': 500, 'learning_rate': 0.1, 'seed': 7, 'n_jobs': 3, 'metrics': ['rmse']}
[02/03/2019 12:27:48 PM (Local Time)] INFO : Run training at: 2019-02-03-12-27-48
[02/03/2019 12:27:49 PM (Local Time)] INFO : Save model artifact C:\Users\zoomz\OneDrive\Documents\GitHub\XLC\LightGBM\LightGBM_model_checkpoints\LightGBM_model_ckpt_2019-02-03-12-27-48
[02/03/2019 12:33:17 PM (Local Time)] INFO : Initial learning rate: 0.1, adjustable learning rates: [0.1, 0.001, 0.0001, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05]
[02/03/2019 12:33:17 PM (Local Time)] INFO : Randomly split training data into 70% to 30%.
[02/03/2019 12:33:17 PM (Local Time)] INFO : Training data size: (354, 13), validation data size: (152, 13)
[02/03/2019 12:33:17 PM (Local Time)] INFO : Booster parameters: {'subsample_for_bin': 200000, 'class_weight': None, 'min_split_gain': 0.0, 'subsample': 1.0, 'num_leaves': 31, 'reg_lambda': 0.0, 'n_estimators': 100, 'boosting_type': 'gbdt', 'min_child_samples': 20, 'colsample_bytree': 1.0, 'subsample_freq': 0, 'max_depth': -1, 'reg_alpha': 0.0, 'min_child_weight': 0.001, 'objective': 'regression', 'num_iterations': 500, 'learning_rate': 0.1, 'seed': 7, 'n_jobs': 6, 'metrics': ['rmse']}
[02/03/2019 12:33:17 PM (Local Time)] INFO : Run training at: 2019-02-03-12-33-17
[02/03/2019 12:33:18 PM (Local Time)] INFO : Save model artifact C:\Users\zoomz\OneDrive\Documents\GitHub\XLC\LightGBM\LightGBM_model_checkpoints\LightGBM_model_ckpt_2019-02-03-12-33-17
[02/03/2019 12:36:57 PM (Local Time)] INFO : Start K-Fold cross validation (ensemble)...
[02/03/2019 12:36:57 PM (Local Time)] INFO : 
For fold 1...

[02/03/2019 12:36:57 PM (Local Time)] INFO : Initial learning rate: 0.0001, adjustable learning rates: None
[02/03/2019 12:36:57 PM (Local Time)] INFO : Training data size: (337, 13)
[02/03/2019 12:36:57 PM (Local Time)] INFO : Will use validation data sets provided by user.
[02/03/2019 12:36:57 PM (Local Time)] INFO : Validation data set size: (169, 13)
[02/03/2019 12:36:57 PM (Local Time)] INFO : Booster parameters: {'subsample_for_bin': 200000, 'class_weight': None, 'min_split_gain': 0.0, 'subsample': 1.0, 'num_leaves': 31, 'reg_lambda': 0.0, 'n_estimators': 100, 'boosting_type': 'gbdt', 'min_child_samples': 20, 'colsample_bytree': 1.0, 'subsample_freq': 0, 'max_depth': -1, 'reg_alpha': 0.0, 'min_child_weight': 0.001, 'objective': 'regression', 'num_iterations': 100, 'learning_rate': 0.0001, 'seed': 7, 'n_jobs': -1, 'metrics': ['rmse']}
[02/03/2019 12:36:57 PM (Local Time)] INFO : Run training at: 2019-02-03-12-36-57
[02/03/2019 12:36:57 PM (Local Time)] INFO : Save model artifact C:\Users\zoomz\OneDrive\Documents\GitHub\XLC\LightGBM\LightGBM_model_checkpoints\LightGBM_model_ckpt_2019-02-03-12-36-57
[02/03/2019 12:36:57 PM (Local Time)] INFO : 
For fold 2...

[02/03/2019 12:36:57 PM (Local Time)] INFO : Initial learning rate: 0.0001, adjustable learning rates: None
[02/03/2019 12:36:57 PM (Local Time)] INFO : Training data size: (337, 13)
[02/03/2019 12:36:57 PM (Local Time)] INFO : Will use validation data sets provided by user.
[02/03/2019 12:36:57 PM (Local Time)] INFO : Validation data set size: (169, 13)
[02/03/2019 12:36:57 PM (Local Time)] INFO : Booster parameters: {'subsample_for_bin': 200000, 'class_weight': None, 'min_split_gain': 0.0, 'subsample': 1.0, 'num_leaves': 31, 'reg_lambda': 0.0, 'n_estimators': 100, 'boosting_type': 'gbdt', 'min_child_samples': 20, 'colsample_bytree': 1.0, 'subsample_freq': 0, 'max_depth': -1, 'reg_alpha': 0.0, 'min_child_weight': 0.001, 'objective': 'regression', 'num_iterations': 100, 'learning_rate': 0.0001, 'seed': 7, 'n_jobs': -1, 'metrics': ['rmse']}
[02/03/2019 12:36:57 PM (Local Time)] INFO : Run training at: 2019-02-03-12-36-57
[02/03/2019 12:36:57 PM (Local Time)] INFO : Save model artifact C:\Users\zoomz\OneDrive\Documents\GitHub\XLC\LightGBM\LightGBM_model_checkpoints\LightGBM_model_ckpt_2019-02-03-12-36-57
[02/03/2019 12:36:57 PM (Local Time)] INFO : 
For fold 3...

[02/03/2019 12:36:57 PM (Local Time)] INFO : Initial learning rate: 0.0001, adjustable learning rates: None
[02/03/2019 12:36:57 PM (Local Time)] INFO : Training data size: (338, 13)
[02/03/2019 12:36:57 PM (Local Time)] INFO : Will use validation data sets provided by user.
[02/03/2019 12:36:57 PM (Local Time)] INFO : Validation data set size: (168, 13)
[02/03/2019 12:36:57 PM (Local Time)] INFO : Booster parameters: {'subsample_for_bin': 200000, 'class_weight': None, 'min_split_gain': 0.0, 'subsample': 1.0, 'num_leaves': 31, 'reg_lambda': 0.0, 'n_estimators': 100, 'boosting_type': 'gbdt', 'min_child_samples': 20, 'colsample_bytree': 1.0, 'subsample_freq': 0, 'max_depth': -1, 'reg_alpha': 0.0, 'min_child_weight': 0.001, 'objective': 'regression', 'num_iterations': 100, 'learning_rate': 0.0001, 'seed': 7, 'n_jobs': -1, 'metrics': ['rmse']}
[02/03/2019 12:36:57 PM (Local Time)] INFO : Run training at: 2019-02-03-12-36-57
[02/03/2019 12:36:57 PM (Local Time)] INFO : Save model artifact C:\Users\zoomz\OneDrive\Documents\GitHub\XLC\LightGBM\LightGBM_model_checkpoints\LightGBM_model_ckpt_2019-02-03-12-36-57
[02/03/2019 12:36:57 PM (Local Time)] INFO : For 3-folds cross validation, the rmse is 9.11616
[02/03/2019 12:37:17 PM (Local Time)] INFO : Start K-Fold cross validation (ensemble)...
[02/03/2019 12:37:17 PM (Local Time)] INFO : 
For fold 1...

[02/03/2019 12:37:17 PM (Local Time)] INFO : Initial learning rate: 0.0001, adjustable learning rates: None
[02/03/2019 12:37:17 PM (Local Time)] INFO : Training data size: (337, 13)
[02/03/2019 12:37:17 PM (Local Time)] INFO : Will use validation data sets provided by user.
[02/03/2019 12:37:17 PM (Local Time)] INFO : Validation data set size: (169, 13)
[02/03/2019 12:37:17 PM (Local Time)] INFO : Booster parameters: {'subsample_for_bin': 200000, 'class_weight': None, 'min_split_gain': 0.0, 'subsample': 1.0, 'num_leaves': 31, 'reg_lambda': 0.0, 'n_estimators': 100, 'boosting_type': 'gbdt', 'min_child_samples': 20, 'colsample_bytree': 1.0, 'subsample_freq': 0, 'max_depth': -1, 'reg_alpha': 0.0, 'min_child_weight': 0.001, 'objective': 'regression', 'num_iterations': 100, 'learning_rate': 0.0001, 'seed': 7, 'n_jobs': -1, 'metrics': ['rmse']}
[02/03/2019 12:37:17 PM (Local Time)] INFO : Run training at: 2019-02-03-12-37-17
[02/03/2019 12:37:17 PM (Local Time)] INFO : Save model artifact C:\Users\zoomz\OneDrive\Documents\GitHub\XLC\LightGBM\LightGBM_model_checkpoints\LightGBM_model_ckpt_2019-02-03-12-37-17
[02/03/2019 12:37:17 PM (Local Time)] INFO : 
For fold 2...

[02/03/2019 12:37:17 PM (Local Time)] INFO : Initial learning rate: 0.0001, adjustable learning rates: None
[02/03/2019 12:37:17 PM (Local Time)] INFO : Training data size: (337, 13)
[02/03/2019 12:37:17 PM (Local Time)] INFO : Will use validation data sets provided by user.
[02/03/2019 12:37:17 PM (Local Time)] INFO : Validation data set size: (169, 13)
[02/03/2019 12:37:17 PM (Local Time)] INFO : Booster parameters: {'subsample_for_bin': 200000, 'class_weight': None, 'min_split_gain': 0.0, 'subsample': 1.0, 'num_leaves': 31, 'reg_lambda': 0.0, 'n_estimators': 100, 'boosting_type': 'gbdt', 'min_child_samples': 20, 'colsample_bytree': 1.0, 'subsample_freq': 0, 'max_depth': -1, 'reg_alpha': 0.0, 'min_child_weight': 0.001, 'objective': 'regression', 'num_iterations': 100, 'learning_rate': 0.0001, 'seed': 7, 'n_jobs': -1, 'metrics': ['rmse']}
[02/03/2019 12:37:17 PM (Local Time)] INFO : Run training at: 2019-02-03-12-37-17
[02/03/2019 12:37:17 PM (Local Time)] INFO : Save model artifact C:\Users\zoomz\OneDrive\Documents\GitHub\XLC\LightGBM\LightGBM_model_checkpoints\LightGBM_model_ckpt_2019-02-03-12-37-17
[02/03/2019 12:37:17 PM (Local Time)] INFO : 
For fold 3...

[02/03/2019 12:37:17 PM (Local Time)] INFO : Initial learning rate: 0.0001, adjustable learning rates: None
[02/03/2019 12:37:17 PM (Local Time)] INFO : Training data size: (338, 13)
[02/03/2019 12:37:17 PM (Local Time)] INFO : Will use validation data sets provided by user.
[02/03/2019 12:37:17 PM (Local Time)] INFO : Validation data set size: (168, 13)
[02/03/2019 12:37:17 PM (Local Time)] INFO : Booster parameters: {'subsample_for_bin': 200000, 'class_weight': None, 'min_split_gain': 0.0, 'subsample': 1.0, 'num_leaves': 31, 'reg_lambda': 0.0, 'n_estimators': 100, 'boosting_type': 'gbdt', 'min_child_samples': 20, 'colsample_bytree': 1.0, 'subsample_freq': 0, 'max_depth': -1, 'reg_alpha': 0.0, 'min_child_weight': 0.001, 'objective': 'regression', 'num_iterations': 100, 'learning_rate': 0.0001, 'seed': 7, 'n_jobs': -1, 'metrics': ['rmse']}
[02/03/2019 12:37:17 PM (Local Time)] INFO : Run training at: 2019-02-03-12-37-17
[02/03/2019 12:37:17 PM (Local Time)] INFO : Save model artifact C:\Users\zoomz\OneDrive\Documents\GitHub\XLC\LightGBM\LightGBM_model_checkpoints\LightGBM_model_ckpt_2019-02-03-12-37-17
[02/03/2019 12:37:17 PM (Local Time)] INFO : For 3-folds cross validation, the rmse is 9.11616
