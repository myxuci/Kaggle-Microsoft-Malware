{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#libraries\n",
    "import numpy as np \n",
    "from numba import jit\n",
    "import pandas as pd \n",
    "from datetime import datetime as dt\n",
    "import os\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import time\n",
    "import datetime\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error, roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn import metrics\n",
    "import gc\n",
    "from catboost import CatBoostClassifier\n",
    "from tqdm import tqdm_notebook\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(filename='log.txt',level=logging.DEBUG, format='%(asctime)s %(message)s')\n",
    "\n",
    "pd.set_option('max_colwidth', 500)\n",
    "pd.set_option('max_columns', 500)\n",
    "pd.set_option('max_rows', 100)\n",
    "import os\n",
    "from dtypes import *\n",
    "from utils import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6c35d7905d103434a82e43cb9f3ef29de6630cb7"
   },
   "outputs": [],
   "source": [
    "numerics = ['int8', 'int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "numerical_columns = [c for c,v in dtypes.items() if v in numerics]\n",
    "categorical_columns = [c for c,v in dtypes.items() if v not in numerics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ce3aae0f20871c76cd8ea196f641bbdb1e43f09e"
   },
   "outputs": [],
   "source": [
    "print('Download Train and Test Data.\\n')\n",
    "train = pd.read_csv('D:/Kaggle/Microsoft Malware Prediction/Data/train.csv', dtype=dtypes)\n",
    "train['MachineIdentifier'] = train.index.astype('uint32')\n",
    "train['AvSigVersion'] = train['AvSigVersion'].cat.add_categories('1.203.1144.0')\n",
    "train.loc[5244810, 'AvSigVersion'] = '1.203.1144.0'\n",
    "\n",
    "test  = pd.read_csv('D:/Kaggle/Microsoft Malware Prediction/Data/test.csv',  dtype=dtypes)\n",
    "test['MachineIdentifier']  = test.index.astype('uint32')\n",
    "test.loc[6529507, 'OsBuildLab'] = '17134.1.amd64fre.rs4_release.180410-1804'\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6b0a786abeeef1bc4c037fa4e5dc608a1adb6a90"
   },
   "outputs": [],
   "source": [
    "random_sample_percent = 5/8\n",
    "random_state = 15\n",
    "number_of_folds = 5\n",
    "stop_after_fold_number = 1\n",
    "shuffle = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "dc3cef46c5a11c0ce43e5e5833f767d80be9b036"
   },
   "outputs": [],
   "source": [
    "# To match the R kernel - https://www.kaggle.com/hung96ad/lightgbm\n",
    "if random_sample_percent is not None:\n",
    "    train = train.sample(frac=random_sample_percent, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "45fb8d5d8ae977b761bbbd455a7be038ed0ac0b3"
   },
   "outputs": [],
   "source": [
    "train_y = train['HasDetections']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9b30845cb2f7617360afc9be7677c51ffa74a5bb"
   },
   "outputs": [],
   "source": [
    "train = reduce_mem_usage(train)\n",
    "test = reduce_mem_usage(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "97059a4739c8867a91ffaf0376e19533e3d111b7"
   },
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9401a8d33d172c46cbe8b3fd882348499fd40bf0"
   },
   "outputs": [],
   "source": [
    "def encode_categorical_columns(x_train, x_test, columns, sort=True):\n",
    "    train_length = x_train.shape[0]\n",
    "    for col in tqdm(columns):\n",
    "        if col == 'MachineIdentifier' or col == 'HasDetections':\n",
    "            continue\n",
    "            \n",
    "        combined_data = pd.concat([x_train[col], x_test[col]])\n",
    "        combined_data, _ = pd.factorize(combined_data, sort=sort)\n",
    "        combined_data = pd.Series(combined_data).astype('int32')\n",
    "        x_train[col] = combined_data.iloc[:train_length].values\n",
    "        x_test[col] = combined_data.iloc[train_length:].values\n",
    "        x_train[col] = x_train[col].fillna(0)\n",
    "        x_test[col] = x_test[col].fillna(0)\n",
    "        del combined_data\n",
    "        gc.collect()\n",
    "        \n",
    "    return x_train, x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d82f3fa8e4276baf6f17fa1c883625bbfda72266"
   },
   "outputs": [],
   "source": [
    "train, test = encode_categorical_columns(train, test, categorical_columns)\n",
    "train = reduce_mem_usage(train)\n",
    "test = reduce_mem_usage(test)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fb0e069963a201882919c87ea9d4fc1e90031dcc"
   },
   "outputs": [],
   "source": [
    "# idea from this kernel: https://www.kaggle.com/fabiendaniel/detecting-malwares-with-lgbm\n",
    "def predict_chunk(model, test):\n",
    "    initial_idx = 0\n",
    "    chunk_size = 1000000\n",
    "    current_pred = np.zeros(len(test))\n",
    "    while initial_idx < test.shape[0]:\n",
    "        final_idx = min(initial_idx + chunk_size, test.shape[0])\n",
    "        idx = range(initial_idx, final_idx)\n",
    "        current_pred[idx] = model.predict(test.iloc[idx], num_iteration=model.best_iteration)\n",
    "        initial_idx = final_idx\n",
    "    #predictions += current_pred / min(folds.n_splits, max_iter)\n",
    "    return current_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c310383c43a1e2eaabb6a7261660fe816ea3aab1"
   },
   "outputs": [],
   "source": [
    "def train_model(x, \n",
    "                y, \n",
    "                lgb_params, \n",
    "                number_of_folds=5, \n",
    "                evaluation_metric='auc', \n",
    "                save_feature_importances=False, \n",
    "                early_stopping_rounds=50, \n",
    "                num_round = 50,\n",
    "                identifier_columns=['MachineIdentifier'],\n",
    "                stop_after_fold_number=None):\n",
    "    \n",
    "    cross_validator = StratifiedKFold(n_splits=number_of_folds,\n",
    "                                  random_state=random_state,\n",
    "                                  shuffle=shuffle)\n",
    "    \n",
    "    validation_scores = []\n",
    "    classifier_models = []\n",
    "    feature_importance_df = pd.DataFrame()\n",
    "    for fold_index, (train_index, validation_index) in enumerate(cross_validator.split(x, y)):\n",
    "        x_train, x_validation = x.iloc[train_index], x.iloc[validation_index]\n",
    "        y_train, y_validation = y.iloc[train_index], y.iloc[validation_index]\n",
    "    \n",
    "        x_train.drop(identifier_columns, axis=1, inplace=True)\n",
    "        validation_identifier_data = x_validation[identifier_columns]\n",
    "        x_validation.drop(identifier_columns, axis=1, inplace=True)\n",
    "        x_train_columns = x_train.columns\n",
    "        trn_data = lgb.Dataset(x_train,\n",
    "                       label=y_train,\n",
    "                       # categorical_feature=categorical_columns\n",
    "                       )\n",
    "        del x_train\n",
    "        del y_train\n",
    "        val_data = lgb.Dataset(x_validation,\n",
    "                               label=y_validation,\n",
    "                               # categorical_feature=categorical_columns\n",
    "                               )\n",
    "        \n",
    "        classifier_model = lgb.train(lgb_params,\n",
    "                                     trn_data,\n",
    "                                      num_round,\n",
    "                                     valid_sets=[trn_data, val_data],\n",
    "                                     verbose_eval=100,\n",
    "                                     early_stopping_rounds=early_stopping_rounds,\n",
    "                                     feval=eval_auc\n",
    "                                     )\n",
    "\n",
    "        classifier_models.append(classifier_model)\n",
    "        \n",
    "        predictions = classifier_model.predict(x_validation, num_iteration=classifier_model.best_iteration)\n",
    "        false_positive_rate, recall, thresholds = metrics.roc_curve(y_validation, predictions)\n",
    "        score = metrics.auc(false_positive_rate, recall)\n",
    "        validation_scores.append(score)\n",
    "        \n",
    "        fold_importance_df = pd.DataFrame()\n",
    "        fold_importance_df[\"feature\"] = x_train_columns\n",
    "        fold_importance_df[\"importance\"] = classifier_model.feature_importance(importance_type='gain')\n",
    "        fold_importance_df[\"fold\"] = fold_index + 1\n",
    "        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "\n",
    "        if stop_after_fold_number == fold_index + 1:\n",
    "            break\n",
    "    if save_feature_importances:\n",
    "        cols = (feature_importance_df[[\"feature\", \"importance\"]]\n",
    "                .groupby(\"feature\")\n",
    "                .mean()\n",
    "                .sort_values(by=\"importance\", ascending=False)[:1000].index)\n",
    "\n",
    "        best_features = feature_importance_df.loc[feature_importance_df.feature.isin(cols)]\n",
    "\n",
    "        plt.figure(figsize=(14, 25))\n",
    "        sns.barplot(x=\"importance\",\n",
    "                    y=\"feature\",\n",
    "                    data=best_features.sort_values(by=\"importance\",\n",
    "                                                   ascending=False))\n",
    "        plt.title('LightGBM Features (avg over folds)')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('lgbm_importances.png')\n",
    "\n",
    "        # mean_gain = feature_importances[['gain', 'feature']].groupby('feature').mean()\n",
    "        # feature_importances['mean_gain'] = feature_importances['feature'].map(mean_gain['gain'])\n",
    "        #\n",
    "        # temp = feature_importances.sort_values('mean_gain', ascending=False)\n",
    "        best_features.sort_values(by=\"importance\", ascending=False) \\\n",
    "            .groupby(\"feature\") \\\n",
    "            .mean() \\\n",
    "            .sort_values(by=\"importance\", ascending=False) \\\n",
    "            .to_csv('feature_importances_new.csv', index=True)\n",
    "\n",
    "    score = sum(validation_scores) / len(validation_scores)\n",
    "    return classifier_models, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "724b764ce4f2b3e9b84371eafda167804254cd30"
   },
   "outputs": [],
   "source": [
    "# # params from https://www.kaggle.com/fabiendaniel/detecting-malwares-with-lgbm\n",
    "# params = {'num_leaves': 128,\n",
    "#          'min_data_in_leaf': 42,\n",
    "#          'objective': 'binary',\n",
    "#          'max_depth': -1,\n",
    "#          'learning_rate': 0.05,\n",
    "#          \"boosting\": \"gbdt\",\n",
    "#          \"feature_fraction\": 0.8,\n",
    "#          \"bagging_freq\": 5,\n",
    "#          \"bagging_fraction\": 0.8,\n",
    "#          \"bagging_seed\": 11,\n",
    "#          \"lambda_l1\": 0.15,\n",
    "#          \"lambda_l2\": 0.15,\n",
    "#          \"random_state\": 42,          \n",
    "#          \"verbosity\": -1}\n",
    "\n",
    "base_params = {   \n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'binary',\n",
    "        'metric': 'auc',\n",
    "        'nthread': -1,\n",
    "        'learning_rate': 0.05,\n",
    "        'max_depth': 5,\n",
    "        'num_leaves': 40,\n",
    "        'sub_feature': 0.9,\n",
    "        'sub_row':0.9,\n",
    "        'bagging_freq': 1,\n",
    "        'lambda_l1': 0.1,\n",
    "        'lambda_l2': 0.1,\n",
    "        'random_state': random_state\n",
    "        }\n",
    "# base_params = {'objective':'binary', \n",
    "#                \"boosting\": \"gbdt\", \n",
    "#                'learning_rate': 0.02, \n",
    "#                'max_depth': -1,\n",
    "#                \"feature_fraction\": 0.8, \n",
    "#                \"bagging_freq\": 1, \n",
    "#                \"bagging_fraction\": 0.8 , \n",
    "#                \"bagging_seed\": 11,\n",
    "#                \"metric\": 'auc', \n",
    "#                \"lambda_l1\": 0.1, \n",
    "#                'num_leaves': 60, \n",
    "#                'min_data_in_leaf': 60, \n",
    "#                \"verbosity\": -1, \n",
    "#                \"random_state\": random_state\n",
    "#               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c62eddee25bfc53f892e213069ed13def5330bcd"
   },
   "outputs": [],
   "source": [
    "models, validation_score = train_model(train.drop('HasDetections', axis=1),\n",
    "                                      train_y, base_params,\n",
    "                                      num_round=5120,\n",
    "                                      early_stopping_rounds=200,\n",
    "                                      stop_after_fold_number=stop_after_fold_number,\n",
    "                                      save_feature_importances=True)\n",
    "del train\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "af125cb2b7b53bf8cd78d53432713cada965cf92"
   },
   "outputs": [],
   "source": [
    "submission_data = test[['MachineIdentifier']]\n",
    "predictions = np.zeros(len(test))\n",
    "test = test.drop('MachineIdentifier', axis=1)\n",
    "chunk_size = 1000000\n",
    "for classifier_model in tqdm(models):\n",
    "    current_pred = np.zeros(len(test))\n",
    "    initial_idx = 0\n",
    "    while initial_idx < test.shape[0]:\n",
    "        final_idx = min(initial_idx + chunk_size, test.shape[0])\n",
    "        idx = range(initial_idx, final_idx)\n",
    "        current_pred[idx] = classifier_model.predict(test.iloc[idx],\n",
    "                                                     num_iteration=classifier_model.best_iteration)\n",
    "        initial_idx = final_idx\n",
    "\n",
    "    predictions += current_pred / len(models)\n",
    "del test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b55d932d250dc1d9f8b6fdb1e994b782e8f645cd"
   },
   "outputs": [],
   "source": [
    "submission_data['HasDetections'] = predictions\n",
    "filename = 'submission_{:.6f}_{}_folds_{}_data.csv'.format(validation_score,\n",
    "                                                              dt.now().strftime('%Y-%m-%d-%H-%M'),\n",
    "                                                              len(models))\n",
    "submission_data.to_csv('single_{}'.format(filename), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
